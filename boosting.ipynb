{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Check Questions</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответе на вопросы своими словами, если не выходит, то вернитесь к лекции дополнительным материалам:\n",
    "\n",
    "**Вопрос 1**: В каком пространстве градиентный бустинг совершает градиентный спуск? Какова размерность этого пространства?\n",
    "\n",
    "В пространстве меток объектов, размерность- количество меток объектов\n",
    "\n",
    "**Вопрос 2**: Почему бустинг над глубокими деревьями это плохая идея?\n",
    "\n",
    "Существует большая вероятность переобучения\n",
    "\n",
    "**Вопрос 3**: Что предсказывает каждое дерево (что является признаками а что целевой переменной?)\n",
    "\n",
    "Признаки - параметры объектов, целевая переменная - класс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Binary Boosting Implementation</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте вспомним бустинг\n",
    "\n",
    "#### Градиентный спуск\n",
    "\n",
    "Самый простой метод минимизации функции, для оптимизации в каждый момент времени двигаемся по антиградиенту функции с каким-то шагом. \n",
    "\n",
    "$$w_{n+1} = w_n - s \\cdot \\frac{\\partial f}{\\partial w}$$\n",
    "\n",
    "#### Градиентный бустинг\n",
    "\n",
    "Теперь давайте представим, что на каждом шаге мы оптимизируем не параметры алгоритма $w$, а ответы нашего алгоритма $\\hat{y}$.\n",
    "\n",
    "**Обучение**: На каждом шаге, давайте предсказывать градиент на каждом объекте и \"двигать\" ответ в сторону улучшения (антиградиента).\n",
    "\n",
    "**Алгоритм**:\n",
    "- Первый алгоритм отвечает константу \n",
    "- Добавляем базовые алгоритмы $b_i$, $i = 1, .., N$:\n",
    "    - $\\hat{y} = \\sum_{j=0}^{i-1} a_j b_j(x)$\n",
    "    - Вычисляем градиент функции потерь ПО ОТВЕТАМ модели $g_{i-1} = \\frac{\\partial L(\\hat{y},~~y)}{\\partial \\hat{y}}$ на каждом объекте  \n",
    "    - Обучаем $b_i$ предсказывать текущий $g_{i-1}$ (Тут дерево не глубокое регрессионное дерево)\n",
    "    - Дополняем композицию $\\sum_{j=0}^{i-1} a_j b_j (x) + lr * b_i(x)$\n",
    "    \n",
    "    \n",
    "#### Нужно реализовать двух классовый бустинг с логистической функцией потерь.     \n",
    "\n",
    "**Функция потерь**:\n",
    "Я вот думаю, что всем интересно какую-же функцию потерь выбрать $\\mathcal{L}(\\hat{y},y)=\\log\\left( 1 + e^{-\\hat{y}y} \\right)$\n",
    "\n",
    "тут важный момент есть, даже не один\n",
    "- $\\hat{y}$ -- это ответ композиции, тоесть сумма ответов всех предыдущих деревьев\n",
    "- Это скалярная функция и производная халява, но вот тут мы вам посчитали $$\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}} = \\frac{1}{1 + e^{-y\\hat{y}}} \\cdot (-ye^{-y\\hat{y}})=-y\\frac{1}{1 + e^{y\\hat{y}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from utils import plot_surface\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import math\n",
    "import scipy\n",
    "from sklearn import tree\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BinaryBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators, lr=0.1):\n",
    "        self.lr = lr\n",
    "        self.n_estimators = n_estimators\n",
    "\n",
    "    def loss_grad(self, original_y, pred_y):\n",
    "        #print(np.dot( np.array(original_y), np.array(pred_y) ))\n",
    "        return np.array(original_y, )*(-scipy.special.expit( np.dot( - np.array(original_y), np.array(pred_y) )))\n",
    "        #return np.array(original_y, ) * (-1) / float( 1 + math.exp( np.dot( np.array(original_y), np.array(pred_y) )) )\n",
    "    \n",
    "\n",
    "    def fit(self, X, original_y):\n",
    "        clf = tree.DecisionTreeRegressor()\n",
    "        clf = clf.fit(X, original_y)\n",
    "        self.estimators_ = [clf]\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            grad = self.loss_grad(original_y, self._predict(X))\n",
    "\n",
    "            estimator = tree.DecisionTreeRegressor()\n",
    "            estimator = estimator.fit(X, grad)\n",
    "            self.estimators_.append(estimator)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X):\n",
    "\n",
    "        y_pred = self.estimators_[0].predict(X)\n",
    "        for i in range(1, len(self.estimators_)):\n",
    "            y_pred = y_pred  - self.lr * self.estimators_[i].predict(X)\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        y_pred_not_norm = self._predict(X)\n",
    "        y_pred = [0] * len(y_pred_not_norm)\n",
    "        for i in range(len(y_pred_not_norm)):\n",
    "            if y_pred_not_norm[i] >= 0:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = -1\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Simple test</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=2,\n",
    "                           n_informative=2, n_redundant=0, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=2,\n",
    "                           flip_y=0.05, class_sep=0.8, random_state=241)\n",
    "y = 2*(y-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814407203602\n",
      "0.867433716858\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "clf = BinaryBoostingClassifier(n_estimators=150).fit(X[0:30000], y[0:30000])\n",
    "print(sklearn.metrics.accuracy_score(y[30001:32000], clf.predict(X[30001:32000]) ))\n",
    "clf = sklearn.ensemble.GradientBoostingClassifier()\n",
    "clf.fit(X[0:30000], y[0:30000])\n",
    "y_pred = clf.predict(X[30001:32000])\n",
    "print(sklearn.metrics.accuracy_score(y[30001:32000], y_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Adult test</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Скачайте https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult = pd.read_csv(\n",
    "    'adult.data', \n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"cdCapital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"], \n",
    "    header=None, na_values=\"?\")\n",
    "adult = pd.get_dummies(adult)\n",
    "adult[\"Target\"] = adult[\"Target_ >50K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = adult[adult.columns[:-3]].values, adult[adult.columns[-1]].values\n",
    "y = 2*(y-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-08390be21502>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-08390be21502>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <Сверьте качество своего алгоритма с GradientBoostingClassifier, оно должно быть примерно таким-же>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<Сверьте качество своего алгоритма с GradientBoostingClassifier, оно должно быть примерно таким-же>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8367363947\n",
      "0.808984082007\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "clf = sklearn.ensemble.GradientBoostingClassifier()\n",
    "clf.fit(X[0:500], y[0:500])\n",
    "y_pred = clf.predict(X[20001:32000])\n",
    "print(sklearn.metrics.accuracy_score(y[20001:32000], y_pred ))\n",
    "clf = BinaryBoostingClassifier(n_estimators=100).fit(X[0:500], y[0:500])\n",
    "print(sklearn.metrics.accuracy_score(y[20001:32000], clf.predict(X[20001:32000]) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Сдача ДЗ</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполните форму https://goo.gl/forms/sPE6gpRDNTOXQai12 \n",
    "    - Качество вашего алгоритма на adult, один знак после запятой, без округления (0.86 -> 0.8 и тд) точность\n",
    "    - BinaryBoostingClassifier.loss_grad ([-1, 1, 1], [-1, 1, -1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2689414213699951"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BinaryBoostingClassifier(n_estimators=100).loss_grad ([-1, 1, 1], [-1, 1, -1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    39,  77516,     13, ...,      1,      0,      0],\n",
       "       [    50,  83311,     13, ...,      1,      0,      0],\n",
       "       [    38, 215646,      9, ...,      1,      0,      0],\n",
       "       ..., \n",
       "       [    58, 151910,      9, ...,      1,      0,      0],\n",
       "       [    22, 201490,      9, ...,      1,      0,      0],\n",
       "       [    52, 287927,      9, ...,      1,      0,      0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
